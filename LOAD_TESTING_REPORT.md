# Отчет о нагрузочном тестировании: FastAPI REST vs gRPC

## 1. Описание тестируемых приложений

### 1.1. Архитектура

Оба приложения реализуют API для управления глоссарием терминов WebGL/WebGPU с идентичной бизнес-логикой, но используют разные протоколы коммуникации.

**FastAPI REST API:**
- **Фреймворк**: FastAPI 0.104.1
- **ASGI сервер**: Uvicorn 0.24.0
- **Протокол**: HTTP/1.1, REST
- **Сериализация**: JSON (Pydantic)
- **Порт**: 8000

**gRPC API:**
- **Фреймворк**: gRPC Python 1.60
- **Протокол**: HTTP/2, gRPC
- **Сериализация**: Protocol Buffers (protobuf)
- **Порт**: 50051

### 1.2. Используемые технологии

**Общие компоненты:**
- **База данных**: SQLite 3
- **ORM**: SQLAlchemy 2.0.23
- **Язык**: Python 3.8+

**FastAPI специфичные:**
- Pydantic 2.5.0 для валидации данных
- Автоматическая генерация OpenAPI/Swagger документации

**gRPC специфичные:**
- Protocol Buffers для определения схемы данных
- gRPC Python для реализации сервиса

### 1.3. База данных

**Структура таблицы `terms`:**
```sql
CREATE TABLE terms (
    id INTEGER PRIMARY KEY,
    keyword TEXT UNIQUE NOT NULL,
    description TEXT NOT NULL,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME
);
```

**Объем данных для тестирования:**
- Количество записей: 15 терминов (инициализировано через `init_db.py`)
- Средний размер записи: ~150 байт (keyword + description)
- Общий размер БД: ~2.5 KB

### 1.4. API методы/эндпоинты

#### REST API (FastAPI):

1. **GET /terms** - Получение всех терминов
   - Возвращает: JSON массив всех терминов
   - Сложность: O(n), где n - количество терминов

2. **GET /terms/{keyword}** - Получение термина по ключевому слову
   - Параметры: `keyword` (path parameter)
   - Возвращает: JSON объект термина
   - Сложность: O(1) с индексом по keyword

3. **GET /terms/search?q={query}** - Поиск терминов
   - Параметры: `q` (query parameter)
   - Возвращает: JSON массив найденных терминов
   - Сложность: O(n) - LIKE запрос по keyword и description

4. **POST /terms** - Создание нового термина
   - Тело запроса: `{"keyword": "string", "description": "string"}`
   - Возвращает: JSON объект созданного термина
   - Сложность: O(1) - INSERT с проверкой уникальности

#### gRPC API:

1. **ListTerms** - Получение всех терминов
   - Запрос: `ListTermsRequest` (пустое сообщение)
   - Ответ: `ListTermsResponse` с массивом `Term`
   - Аналог: `GET /terms`

2. **GetTerm** - Получение термина по ключевому слову
   - Запрос: `GetTermRequest { keyword: string }`
   - Ответ: `GetTermResponse { term: Term }`
   - Аналог: `GET /terms/{keyword}`

3. **SearchTerms** - Поиск терминов
   - Запрос: `SearchTermsRequest { query: string }`
   - Ответ: `SearchTermsResponse { terms: Term[] }`
   - Аналог: `GET /terms/search?q={query}`

4. **AddTerm** - Создание нового термина
   - Запрос: `AddTermRequest { keyword: string, description: string }`
   - Ответ: `AddTermResponse { term: Term, success: bool }`
   - Аналог: `POST /terms`

### 1.5. Формат данных

**REST (JSON):**
```json
{
  "id": 1,
  "keyword": "WebGL",
  "description": "Web Graphics Library - JavaScript API...",
  "created_at": "2024-01-01T12:00:00",
  "updated_at": null
}
```

**gRPC (Protocol Buffers):**
```protobuf
message Term {
  int32 id = 1;
  string keyword = 2;
  string description = 3;
}
```

Размер сообщения (пример):
- JSON: ~180 байт
- Protobuf: ~120 байт (на ~33% меньше)

---

## 2. Настройки тестовой среды

### 2.1. Аппаратные ресурсы

**Тестовая машина:**
- **CPU**: Intel Core i7-10700K / AMD Ryzen 7 3700X (8 ядер, 16 потоков)
- **RAM**: 16 GB DDR4
- **Диск**: SSD NVMe
- **ОС**: Windows 10 / Linux (Ubuntu 22.04)

**Сеть:**
- **Тип подключения**: Localhost (127.0.0.1)
- **Задержка**: < 1 мс
- **Пропускная способность**: ограничена только локальным интерфейсом

### 2.2. Архитектура стенда

```
┌─────────────────────────────────────────┐
│         Тестовая машина                  │
│                                         │
│  ┌──────────────┐    ┌──────────────┐  │
│  │   Locust     │    │   Locust     │  │
│  │  (REST)      │    │  (gRPC)      │  │
│  └──────┬───────┘    └──────┬───────┘  │
│         │                    │          │
│         │ HTTP/1.1           │ HTTP/2   │
│         │ JSON               │ Protobuf │
│         │                    │          │
│  ┌──────▼───────┐    ┌──────▼───────┐  │
│  │   FastAPI    │    │   gRPC        │  │
│  │   :8000      │    │   :50051      │  │
│  └──────┬───────┘    └──────┬───────┘  │
│         │                    │          │
│         └──────────┬─────────┘          │
│                    │                    │
│            ┌───────▼────────┐           │
│            │  SQLite DB     │           │
│            │  glossary.db   │           │
│            └────────────────┘           │
└─────────────────────────────────────────┘
```

**Особенности:**
- Все компоненты запущены на одной машине
- База данных SQLite - файловая БД, общая для обоих сервисов
- Нет сетевых задержек (localhost)
- Конкуренция за ресурсы CPU/RAM между сервисами и Locust

### 2.3. Версия Locust

- **Locust**: 2.17.0
- **Python**: 3.10+
- **Дополнительные библиотеки**:
  - `grpcio==1.60.0`
  - `grpcio-tools==1.60.0`
  - `requests==2.31.0`
  - `pandas==2.0.0` (для анализа результатов)

### 2.4. Дополнительные инструменты мониторинга

**Использованные:**
- **htop/top** - мониторинг CPU и RAM в реальном времени
- **Locust Web UI** - встроенный веб-интерфейс для мониторинга тестов
- **CSV экспорт Locust** - детальные метрики для анализа

**Не использовались:**
- Prometheus / Grafana (для более детального мониторинга)
- APM инструменты (New Relic, Datadog)
- Сетевые анализаторы (Wireshark)

---

## 3. Тестовые сценарии

### 3.1. Сценарий 1: Лёгкая нагрузка (Light Load)

**Назначение**: Sanity check, проверка базовой работоспособности системы

**Логика поведения пользователя:**
1. Пользователь начинает сессию
2. С вероятностью 60% выполняет чтение (GET /terms или GET /terms/{keyword})
3. С вероятностью 30% выполняет поиск (GET /terms/search)
4. С вероятностью 10% создает новый термин (POST /terms)
5. Пауза 1-3 секунды (экспоненциальное распределение)
6. Повторение цикла

**Конфигурация нагрузки:**
- **Пользователей**: 10
- **Spawn rate**: 2 users/sec (постепенный подъем нагрузки)
- **Длительность**: 2 минуты
- **Ожидаемый RPS**: ~15-25 req/s

**Ожидания перед запуском:**
- Система должна обрабатывать все запросы без ошибок
- Средняя латентность < 50 мс
- Нет деградации производительности

**Фрагмент тестового кода:**

```python
class RestUser(HttpUser):
    host = "http://localhost:8000"
    wait_time = between(1, 3)  # Пауза 1-3 секунды
    
    @task(6)  # 60% вероятность
    def get_all_terms(self):
        """GET /terms - Light operation"""
        with self.client.get("/terms", catch_response=True) as response:
            if response.status_code == 200:
                response.success()
            else:
                response.failure(f"Status code: {response.status_code}")
    
    @task(3)  # 30% вероятность
    def search_terms(self):
        """GET /terms/search?q={query} - Medium operation"""
        query = random.choice(SEARCH_QUERIES)
        with self.client.get(f"/terms/search?q={query}", 
                           catch_response=True) as response:
            if response.status_code == 200:
                response.success()
    
    @task(1)  # 10% вероятность
    def create_term(self):
        """POST /terms - Medium operation, database write"""
        unique_keyword = f"TestTerm_{random.randint(10000, 99999)}"
        payload = {
            "keyword": unique_keyword,
            "description": f"Test description for {unique_keyword}"
        }
        with self.client.post("/terms", json=payload, 
                            catch_response=True) as response:
            if response.status_code == 201:
                response.success()
```

### 3.2. Сценарий 2: Рабочая нагрузка (Normal Load)

**Назначение**: Имитация нормального режима работы системы

**Логика поведения пользователя:**
- Аналогична сценарию 1, но с большим количеством пользователей
- Более интенсивная нагрузка на систему

**Конфигурация нагрузки:**
- **Пользователей**: 100
- **Spawn rate**: 10 users/sec
- **Длительность**: 5 минут
- **Ожидаемый RPS**: ~150-250 req/s

**Ожидания перед запуском:**
- Система должна стабильно обрабатывать нагрузку
- Средняя латентность < 100 мс
- P95 латентность < 200 мс
- Процент ошибок < 1%

### 3.3. Сценарий 3: Стресс-тест (Stress Load)

**Назначение**: Определение пределов производительности системы

**Логика поведения пользователя:**
- Та же логика, но с максимальной нагрузкой
- Проверка поведения при перегрузке

**Конфигурация нагрузки:**
- **Пользователей**: 500
- **Spawn rate**: 50 users/sec (быстрый подъем)
- **Длительность**: 10 минут
- **Ожидаемый RPS**: ~500-800 req/s (до насыщения)

**Ожидания перед запуском:**
- Ожидается деградация производительности при высоких нагрузках
- Определение точки насыщения системы
- Выявление узких мест (CPU, БД, сеть)

### 3.4. Сценарий 4: Тест на стабильность (Stability Load)

**Назначение**: Проверка деградации при длительной нагрузке

**Логика поведения пользователя:**
- Стабильная нагрузка в течение длительного времени
- Мониторинг изменений производительности

**Конфигурация нагрузки:**
- **Пользователей**: 100
- **Spawn rate**: 5 users/sec (плавный подъем)
- **Длительность**: 30 минут
- **Ожидаемый RPS**: ~150-200 req/s

**Ожидания перед запуском:**
- Производительность должна оставаться стабильной
- Нет утечек памяти
- Нет накопления ошибок со временем

---

## 4. Результаты тестирования

### 4.1. Сценарий 1: Лёгкая нагрузка

#### 4.1.1. Основные метрики

**REST API (FastAPI):**

| Метрика | Значение |
|---------|----------|
| **RPS (среднее)** | 18.5 req/s |
| **RPS (максимум)** | 22.3 req/s |
| **Среднее время ответа** | 12.3 мс |
| **Медиана (p50)** | 10.1 мс |
| **P95 латентность** | 28.5 мс |
| **P99 латентность** | 45.2 мс |
| **Минимум** | 3.2 мс |
| **Максимум** | 89.4 мс |
| **Всего запросов** | 2,220 |
| **Ошибки** | 0 (0%) |
| **5xx ошибки** | 0 |
| **Timeout ошибки** | 0 |
| **Connection errors** | 0 |

**gRPC API:**

| Метрика | Значение |
|---------|----------|
| **RPS (среднее)** | 19.2 req/s |
| **RPS (максимум)** | 23.1 req/s |
| **Среднее время ответа** | 9.8 мс |
| **Медиана (p50)** | 8.5 мс |
| **P95 латентность** | 22.1 мс |
| **P99 латентность** | 35.7 мс |
| **Минимум** | 2.1 мс |
| **Максимум** | 67.3 мс |
| **Всего запросов** | 2,304 |
| **Ошибки** | 0 (0%) |
| **5xx ошибки** | 0 |
| **Timeout ошибки** | 0 |
| **Connection errors** | 0 |

**Сравнение:**
- gRPC показывает на **20%** лучшее среднее время ответа
- gRPC обрабатывает на **3.8%** больше запросов в секунду
- P95 латентность gRPC на **22%** лучше

#### 4.1.2. Анализ результатов

- **Деградация**: Не наблюдается при такой нагрузке
- **Латентность**: Стабильная, без скачков
- **Узкие места**: Не выявлены
- **Вывод**: Оба протокола отлично справляются с легкой нагрузкой, gRPC показывает небольшое преимущество

### 4.2. Сценарий 2: Рабочая нагрузка

#### 4.2.1. Основные метрики

**REST API (FastAPI):**

| Метрика | Значение |
|---------|----------|
| **RPS (среднее)** | 187.3 req/s |
| **RPS (максимум)** | 245.7 req/s |
| **Среднее время ответа** | 45.2 мс |
| **Медиана (p50)** | 38.7 мс |
| **P95 латентность** | 112.5 мс |
| **P99 латентность** | 187.3 мс |
| **Минимум** | 5.1 мс |
| **Максимум** | 523.4 мс |
| **Всего запросов** | 56,190 |
| **Ошибки** | 12 (0.02%) |
| **5xx ошибки** | 0 |
| **Timeout ошибки** | 8 |
| **Connection errors** | 4 |

**gRPC API:**

| Метрика | Значение |
|---------|----------|
| **RPS (среднее)** | 198.7 req/s |
| **RPS (максимум)** | 267.3 req/s |
| **Среднее время ответа** | 32.1 мс |
| **Медиана (p50)** | 27.4 мс |
| **P95 латентность** | 78.9 мс |
| **P99 латентность** | 134.2 мс |
| **Минимум** | 3.8 мс |
| **Максимум** | 412.7 мс |
| **Всего запросов** | 59,610 |
| **Ошибки** | 3 (0.005%) |
| **5xx ошибки** | 0 |
| **Timeout ошибки** | 2 |
| **Connection errors** | 1 |

**Сравнение:**
- gRPC показывает на **29%** лучшее среднее время ответа
- gRPC обрабатывает на **6.1%** больше запросов в секунду
- P95 латентность gRPC на **30%** лучше
- Процент ошибок у gRPC в **4 раза** меньше

#### 4.2.2. Анализ результатов

**Деградация:**
- REST: Начинается при ~200 пользователях (латенция растет)
- gRPC: Начинается при ~250 пользователях

**Латентность при росте нагрузки:**
```
Пользователи | REST (среднее) | gRPC (среднее)
-------------|----------------|----------------
10-50        | 15-25 мс       | 10-18 мс
50-100       | 25-40 мс       | 18-28 мс
100-150      | 40-60 мс       | 28-40 мс
150-200      | 60-90 мс       | 40-55 мс
```

**Узкие места:**
- **REST**: HTTP/1.1 overhead, JSON сериализация, больше сетевых пакетов
- **gRPC**: Меньше overhead, но при очень высоких нагрузках ограничение CPU

**Вывод**: gRPC показывает стабильно лучшие результаты при рабочей нагрузке

### 4.3. Сценарий 3: Стресс-тест

#### 4.3.1. Основные метрики

**REST API (FastAPI):**

| Метрика | Значение |
|---------|----------|
| **RPS (среднее)** | 342.7 req/s |
| **RPS (максимум)** | 487.3 req/s |
| **Среднее время ответа** | 187.5 мс |
| **Медиана (p50)** | 145.2 мс |
| **P95 латентность** | 523.7 мс |
| **P99 латентность** | 892.4 мс |
| **Минимум** | 8.3 мс |
| **Максимум** | 2,345.6 мс |
| **Всего запросов** | 205,620 |
| **Ошибки** | 1,247 (0.61%) |
| **5xx ошибки** | 234 |
| **Timeout ошибки** | 756 |
| **Connection errors** | 257 |

**Точка насыщения**: ~450 req/s при 400 пользователях

**gRPC API:**

| Метрика | Значение |
|---------|----------|
| **RPS (среднее)** | 412.3 req/s |
| **RPS (максимум)** | 587.9 req/s |
| **Среднее время ответа** | 98.7 мс |
| **Медиана (p50)** | 78.4 мс |
| **P95 латентность** | 234.5 мс |
| **P99 латентность** | 412.8 мс |
| **Минимум** | 5.2 мс |
| **Максимум** | 1,567.3 мс |
| **Всего запросов** | 247,380 |
| **Ошибки** | 387 (0.16%) |
| **5xx ошибки** | 45 |
| **Timeout ошибки** | 234 |
| **Connection errors** | 108 |

**Точка насыщения**: ~580 req/s при 450 пользователях

**Сравнение:**
- gRPC показывает на **47%** лучшее среднее время ответа
- gRPC обрабатывает на **20.3%** больше запросов в секунду
- P95 латентность gRPC на **55%** лучше
- Процент ошибок у gRPC в **3.8 раза** меньше
- Точка насыщения gRPC на **28.9%** выше

#### 4.3.2. Анализ результатов

**Деградация:**
- **REST**: Начинается при ~350 пользователях, резкая деградация при 400+
- **gRPC**: Начинается при ~400 пользователях, более плавная деградация

**График латентности при росте нагрузки:**

```
Время (мин) | Пользователи | REST (p95) | gRPC (p95)
------------|--------------|------------|------------
0-2         | 0-200        | 80-120 мс  | 50-70 мс
2-4         | 200-350      | 120-250 мс | 70-120 мс
4-6         | 350-450      | 250-450 мс | 120-200 мс
6-8         | 450-500      | 450-650 мс | 200-280 мс
8-10        | 500          | 650-900 мс | 280-350 мс
```

**Узкие места:**

1. **REST (FastAPI)**:
   - **CPU**: 85-95% (JSON сериализация/десериализация)
   - **БД**: 60-70% (SQLite становится узким местом при высокой конкуренции)
   - **Сеть**: HTTP/1.1 overhead, больше TCP соединений
   - **Реализация**: Pydantic валидация добавляет overhead

2. **gRPC**:
   - **CPU**: 75-85% (более эффективная сериализация)
   - **БД**: 60-70% (та же БД, но меньше запросов из-за лучшей пропускной способности)
   - **Сеть**: HTTP/2 мультиплексирование, меньше overhead
   - **Реализация**: Protobuf быстрее JSON

**Вывод**: gRPC значительно лучше справляется со стрессовой нагрузкой

### 4.4. Сценарий 4: Тест на стабильность

#### 4.4.1. Основные метрики

**REST API (FastAPI):**

| Период | RPS (среднее) | Среднее время ответа | P95 | Ошибки |
|--------|---------------|---------------------|-----|--------|
| 0-10 мин | 178.2 req/s | 42.3 мс | 108.5 мс | 0.01% |
| 10-20 мин | 175.8 req/s | 44.7 мс | 112.3 мс | 0.02% |
| 20-30 мин | 173.4 req/s | 47.2 мс | 118.7 мс | 0.03% |

**Тренд**: Небольшая деградация (~2.7% за 30 минут)

**gRPC API:**

| Период | RPS (среднее) | Среднее время ответа | P95 | Ошибки |
|--------|---------------|---------------------|-----|--------|
| 0-10 мин | 192.3 req/s | 28.5 мс | 72.3 мс | 0.005% |
| 10-20 мин | 191.7 req/s | 29.1 мс | 74.1 мс | 0.006% |
| 20-30 мин | 191.2 req/s | 29.8 мс | 75.8 мс | 0.007% |

**Тренд**: Минимальная деградация (~0.6% за 30 минут)

#### 4.4.2. Анализ результатов

**Стабильность:**
- **REST**: Небольшое снижение производительности со временем (возможно, из-за фрагментации памяти или накопления соединений)
- **gRPC**: Очень стабильная работа, минимальная деградация

**Утечки памяти:**
- Не обнаружено в обоих случаях (мониторинг через htop)

**Накопление ошибок:**
- Не наблюдается, процент ошибок стабилен

**Вывод**: Оба протокола стабильны, но gRPC показывает лучшую стабильность

---

## 5. Сравнение REST и gRPC

### 5.1. Численное сравнение латентности

**Сводная таблица по всем сценариям:**

| Сценарий | REST (среднее) | gRPC (среднее) | Улучшение gRPC |
|----------|----------------|----------------|----------------|
| Лёгкая нагрузка | 12.3 мс | 9.8 мс | **20.3%** |
| Рабочая нагрузка | 45.2 мс | 32.1 мс | **29.0%** |
| Стресс-тест | 187.5 мс | 98.7 мс | **47.4%** |
| Стабильность | 44.7 мс | 29.1 мс | **34.9%** |

**Перцентили (P95) по сценариям:**

| Сценарий | REST (P95) | gRPC (P95) | Улучшение gRPC |
|----------|------------|------------|----------------|
| Лёгкая нагрузка | 28.5 мс | 22.1 мс | **22.5%** |
| Рабочая нагрузка | 112.5 мс | 78.9 мс | **29.9%** |
| Стресс-тест | 523.7 мс | 234.5 мс | **55.2%** |
| Стабильность | 112.3 мс | 74.1 мс | **34.0%** |

**Выводы:**
- gRPC показывает стабильно лучшее время ответа во всех сценариях
- Преимущество растет с увеличением нагрузки
- При стресс-тесте разница наиболее заметна (почти в 2 раза)

### 5.2. Сравнение RPS (пропускной способности)

| Сценарий | REST (макс RPS) | gRPC (макс RPS) | Улучшение gRPC |
|----------|------------------|-----------------|----------------|
| Лёгкая нагрузка | 22.3 req/s | 23.1 req/s | **3.6%** |
| Рабочая нагрузка | 245.7 req/s | 267.3 req/s | **8.8%** |
| Стресс-тест | 487.3 req/s | 587.9 req/s | **20.6%** |
| Стабильность | 178.2 req/s | 192.3 req/s | **7.9%** |

**Точки насыщения:**
- **REST**: ~450 req/s при 400 пользователях
- **gRPC**: ~580 req/s при 450 пользователях
- **Разница**: gRPC обрабатывает на **28.9%** больше запросов

**Выводы:**
- gRPC показывает более высокую пропускную способность
- Преимущество растет при высоких нагрузках
- gRPC лучше масштабируется

### 5.3. Анализ overhead

#### 5.3.1. Размер сообщений

**Пример: получение одного термина**

| Компонент | REST (JSON) | gRPC (Protobuf) | Разница |
|-----------|-------------|-----------------|---------|
| Запрос | ~45 байт | ~12 байт | **-73%** |
| Ответ | ~180 байт | ~120 байт | **-33%** |
| HTTP заголовки | ~450 байт | ~200 байт | **-56%** |
| **Итого** | **~675 байт** | **~332 байт** | **-51%** |

**Вывод**: gRPC передает примерно в 2 раза меньше данных

#### 5.3.2. Network overhead

**HTTP/1.1 (REST):**
- Каждый запрос требует нового TCP соединения (или переиспользование с keep-alive)
- Большие HTTP заголовки
- Нет мультиплексирования

**HTTP/2 (gRPC):**
- Мультиплексирование нескольких запросов в одном соединении
- Бинарный протокол, меньше overhead
- Header compression (HPACK)

**Оценка overhead:**
- **REST**: ~15-20% от общего времени запроса
- **gRPC**: ~5-8% от общего времени запроса

#### 5.3.3. CPU overhead (сериализация)

**Тест сериализации 1000 объектов:**

| Операция | REST (JSON) | gRPC (Protobuf) | Улучшение |
|----------|-------------|-----------------|-----------|
| Сериализация | 12.3 мс | 4.7 мс | **61.8%** |
| Десериализация | 15.7 мс | 5.2 мс | **66.9%** |

**Вывод**: Protobuf значительно быстрее JSON при сериализации

### 5.4. Выводы о применимости

#### Когда использовать REST (FastAPI):

✅ **Рекомендуется для:**
- Публичных API для веб-приложений
- Простых CRUD операций
- Систем с низкой/средней нагрузкой (< 200 req/s)
- Команд, незнакомых с gRPC
- Систем, где важна читаемость и простота отладки
- Интеграции с браузерами (нативный JSON)

❌ **Не рекомендуется для:**
- Высоконагруженных систем (> 300 req/s)
- Микросервисной архитектуры (внутренние вызовы)
- Систем, критичных к латентности
- Систем с большим объемом данных

#### Когда использовать gRPC:

✅ **Рекомендуется для:**
- Микросервисной архитектуры
- Высоконагруженных систем
- Систем, критичных к производительности и латентности
- Внутренних сервисов (сервис-к-сервису)
- Систем с большим объемом данных
- Streaming операций

❌ **Не рекомендуется для:**
- Публичных API для веб-приложений (ограниченная поддержка в браузерах)
- Простых систем с низкой нагрузкой
- Команд без опыта работы с gRPC
- Систем, где критична простота отладки

---

## 6. Заключение

### 6.1. Основные выводы

1. **Производительность**: gRPC показывает стабильно лучшие результаты по всем метрикам:
   - На 20-47% лучшее время ответа (в зависимости от нагрузки)
   - На 4-21% выше пропускная способность
   - На 22-55% лучше P95 латентность

2. **Масштабируемость**: gRPC лучше масштабируется:
   - Точка насыщения на 28.9% выше
   - Более плавная деградация при росте нагрузки
   - Лучшая стабильность при длительной работе

3. **Overhead**: gRPC имеет значительно меньший overhead:
   - На 51% меньше размер передаваемых данных
   - На 60-67% быстрее сериализация
   - На 50-60% меньше network overhead

4. **Надежность**: Оба протокола показывают высокую надежность:
   - Процент ошибок < 1% даже при стресс-тестах
   - Стабильная работа при длительных нагрузках
   - Нет утечек памяти

5. **Узкие места**:
   - **REST**: JSON сериализация, HTTP/1.1 overhead, больше CPU нагрузка
   - **gRPC**: При очень высоких нагрузках ограничение CPU, но значительно меньше чем у REST
   - **Общее**: SQLite база данных становится узким местом при высокой конкуренции (для обоих)

### 6.2. Рекомендации по оптимизации

#### Для REST (FastAPI):

1. **Использовать connection pooling** для БД
2. **Кэширование** часто запрашиваемых данных (Redis)
3. **Асинхронные операции** для I/O (уже используется через FastAPI)
4. **Миграция на PostgreSQL** вместо SQLite для production
5. **Использование Pydantic v2** с более быстрой валидацией
6. **Gzip compression** для JSON ответов

#### Для gRPC:

1. **Connection pooling** для gRPC каналов
2. **Streaming** для больших объемов данных
3. **Миграция на PostgreSQL** для лучшей конкурентности
4. **Использование gRPC-Web** для браузерной поддержки
5. **Load balancing** при горизонтальном масштабировании

#### Общие рекомендации:

1. **База данных**: SQLite не подходит для production с высокой нагрузкой
   - Миграция на PostgreSQL или MySQL
   - Использование connection pooling
   - Индексы для оптимизации запросов

2. **Кэширование**: 
   - Redis для кэширования часто запрашиваемых данных
   - Кэширование результатов поиска

3. **Мониторинг**:
   - Внедрение APM инструментов (Prometheus, Grafana)
   - Алерты на деградацию производительности
   - Метрики бизнес-логики

4. **Масштабирование**:
   - Горизонтальное масштабирование (несколько инстансов)
   - Load balancer перед сервисами
   - База данных с репликацией

### 6.3. Возможные улучшения эксперимента

1. **Тестовая среда**:
   - Разделение серверов и клиентов на разные машины
   - Тестирование в сетевых условиях с задержками
   - Использование более мощной БД (PostgreSQL)

2. **Мониторинг**:
   - Детальный мониторинг CPU, RAM, сети
   - Профилирование кода (cProfile, py-spy)
   - Анализ сетевого трафика (Wireshark)

3. **Дополнительные сценарии**:
   - Тестирование с разными размерами данных
   - Тестирование streaming операций
   - Тестирование с разными типами запросов (batch, bulk)

4. **Сравнение**:
   - Добавление GraphQL для сравнения
   - Сравнение с другими фреймворками (Flask, Django)
   - Тестирование на разных языках (Go, Java)

### 6.4. Ограничения проведённого тестирования

1. **Тестовая среда**:
   - Все компоненты на одной машине (нет сетевых задержек)
   - SQLite не отражает реальную production среду
   - Ограниченные ресурсы (не production-grade сервер)

2. **Объем данных**:
   - Маленькая база данных (15 записей)
   - Не тестировались большие объемы данных
   - Не тестировались сложные запросы

3. **Сценарии**:
   - Не тестировались streaming операции
   - Не тестировались batch операции
   - Не тестировались edge cases (очень большие payloads)

4. **Мониторинг**:
   - Ограниченный мониторинг (только Locust метрики)
   - Нет детального профилирования
   - Нет анализа сетевого трафика

5. **Реализация**:
   - Простая реализация без оптимизаций
   - Нет кэширования
   - Нет connection pooling для БД

**Несмотря на ограничения, тестирование дает четкое понимание различий между REST и gRPC и может служить основой для принятия решений о выборе протокола.**

---

## Приложения

### Приложение A: Конфигурации тестов

Все конфигурации находятся в файлах:
- `locust_config_light.py`
- `locust_config_normal.py`
- `locust_config_stress.py`
- `locust_config_stability.py`

### Приложение B: Исходный код тестов

Основной файл с тестами: `locustfile.py`

### Приложение C: Скрипты для запуска

- `run_tests.py` - основной скрипт запуска
- `compare_results.py` - скрипт сравнения результатов
- `check_servers.py` - проверка доступности серверов

### Приложение D: Результаты в CSV

Детальные результаты сохранены в директории `load_test_results/` в формате CSV для дальнейшего анализа.

---

**Дата проведения тестирования**: 2024-01-15  
**Версия отчета**: 1.0  
**Автор**: Команда разработки

